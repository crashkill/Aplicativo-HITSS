import { Professional } from '../../types/talent/Professional';

export interface AIResponse {
  message: string;
  provider: 'groq' | 'together' | 'llama-free' | 'offline';
  timestamp: Date;
  responseTime?: number;
}

export interface AIProvider {
  name: string;
  isAvailable: () => Promise<boolean>;
  generateResponse: (query: string, context: string) => Promise<string>;
  maxTokens?: number;
  model?: string;
}

// Sistema de IA offline como fallback
class OfflineAI implements AIProvider {
  name = 'offline';
  
  async isAvailable(): Promise<boolean> {
    return true; // Sempre dispon√≠vel
  }

  async generateResponse(query: string, context: string): Promise<string> {
    const lowerQuery = query.toLowerCase();
    
    // An√°lises espec√≠ficas baseadas em palavras-chave
    if (lowerQuery.includes('quantos') || lowerQuery.includes('total')) {
      const lines = context.split('\n').filter(line => line.trim());
      return `Com base nos dados dispon√≠veis, encontrei ${lines.length} registros de profissionais. Posso ajudar voc√™ a filtrar ou analisar informa√ß√µes espec√≠ficas sobre essas pessoas.`;
    }
    
    if (lowerQuery.includes('react') || lowerQuery.includes('javascript') || lowerQuery.includes('typescript')) {
      return `Vejo que voc√™ est√° interessado em profissionais de desenvolvimento frontend/fullstack. Posso ajudar a filtrar por tecnologias espec√≠ficas como React, JavaScript, TypeScript e outras. Que tipo de an√°lise voc√™ gostaria de fazer?`;
    }
    
    if (lowerQuery.includes('senior') || lowerQuery.includes('junior') || lowerQuery.includes('pleno')) {
      return `Para an√°lise de senioridade, posso verificar os n√≠veis de profici√™ncia dos colaboradores. Voc√™ gostaria de ver a distribui√ß√£o por n√≠vel ou encontrar profissionais espec√≠ficos?`;
    }
    
    if (lowerQuery.includes('aws') || lowerQuery.includes('azure') || lowerQuery.includes('cloud')) {
      return `Para profissionais de cloud computing, posso filtrar por AWS, Azure, GCP e outras tecnologias de nuvem. Voc√™ tem alguma prefer√™ncia espec√≠fica de provider?`;
    }
    
    if (lowerQuery.includes('dispon√≠vel') || lowerQuery.includes('compartilhamento')) {
      return `Posso ajudar a identificar profissionais dispon√≠veis para compartilhamento entre projetos. Voc√™ gostaria de ver por percentual de disponibilidade ou localiza√ß√£o?`;
    }
    
    // Resposta padr√£o
    return `Estou aqui para ajudar com an√°lises do banco de talentos! Posso fornecer informa√ß√µes sobre:

‚Ä¢ Quantidade de profissionais por tecnologia
‚Ä¢ Distribui√ß√£o por senioridade e regime de trabalho  
‚Ä¢ Disponibilidade para compartilhamento
‚Ä¢ Localiza√ß√£o e aloca√ß√£o atual
‚Ä¢ An√°lises espec√≠ficas por filtros

O que voc√™ gostaria de saber?`;
  }
}

// Llama 3.3 70B gratuito da Together.xyz
class LlamaFreeAI implements AIProvider {
  name = 'llama-free';
  model = 'meta-llama/Llama-3.3-70B-Instruct-Turbo';
  
  async isAvailable(): Promise<boolean> {
    try {
      const response = await fetch('https://api.together.xyz/v1/models', {
        headers: {
          'Content-Type': 'application/json'
        }
      });
      return response.ok;
    } catch {
      return false;
    }
  }

  async generateResponse(query: string, context: string): Promise<string> {
    const prompt = `Voc√™ √© um assistente especializado em an√°lise de dados de profissionais de TI da HITSS.

DADOS DOS PROFISSIONAIS:
${context}

PERGUNTA DO USU√ÅRIO: ${query}

Instru√ß√µes:
1. Analise os dados fornecidos
2. Responda de forma clara e objetiva
3. Use dados espec√≠ficos quando poss√≠vel
4. Sugira an√°lises ou filtros relevantes
5. Mantenha um tom profissional e √∫til

Resposta:`;

    try {
      const response = await fetch('https://api.together.xyz/v1/chat/completions', {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json'
        },
        body: JSON.stringify({
          model: this.model,
          messages: [
            {
              role: 'user',
              content: prompt
            }
          ],
          max_tokens: 500,
          temperature: 0.7
        })
      });

      if (!response.ok) {
        throw new Error(`HTTP ${response.status}`);
      }

      const data = await response.json();
      return data.choices[0]?.message?.content || 'N√£o foi poss√≠vel gerar uma resposta.';
    } catch (error) {
      throw new Error(`Erro na API Together.xyz: ${error}`);
    }
  }
}

// Groq API
class GroqAI implements AIProvider {
  name = 'groq';
  model = 'llama-3.3-70b-versatile';
  
  private getApiKey(): string | null {
    return import.meta.env.VITE_GROQ_API_KEY || null;
  }
  
  async isAvailable(): Promise<boolean> {
    const apiKey = this.getApiKey();
    if (!apiKey) return false;
    
    try {
      const response = await fetch('https://api.groq.com/openai/v1/models', {
        headers: {
          'Authorization': `Bearer ${apiKey}`,
          'Content-Type': 'application/json'
        }
      });
      return response.ok;
    } catch {
      return false;
    }
  }

  async generateResponse(query: string, context: string): Promise<string> {
    const apiKey = this.getApiKey();
    if (!apiKey) throw new Error('API key n√£o configurada');

    const prompt = `Voc√™ √© um assistente de IA especializado em gest√£o de talentos tecnol√≥gicos da HITSS.

DADOS DISPON√çVEIS:
${context}

PERGUNTA: ${query}

Forne√ßa uma an√°lise clara e acion√°vel baseada nos dados.`;

    try {
      const response = await fetch('https://api.groq.com/openai/v1/chat/completions', {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${apiKey}`,
          'Content-Type': 'application/json'
        },
        body: JSON.stringify({
          model: this.model,
          messages: [
            {
              role: 'user',
              content: prompt
            }
          ],
          max_tokens: 500,
          temperature: 0.7
        })
      });

      if (!response.ok) {
        throw new Error(`HTTP ${response.status}`);
      }

      const data = await response.json();
      return data.choices[0]?.message?.content || 'N√£o foi poss√≠vel gerar uma resposta.';
    } catch (error) {
      throw new Error(`Erro na API Groq: ${error}`);
    }
  }
}

// Together.xyz Premium
class TogetherAI implements AIProvider {
  name = 'together';
  model = 'meta-llama/Llama-3.3-70B-Instruct-Turbo';
  
  private getApiKey(): string | null {
    return import.meta.env.VITE_TOGETHER_API_KEY || null;
  }
  
  async isAvailable(): Promise<boolean> {
    const apiKey = this.getApiKey();
    if (!apiKey) return false;
    
    try {
      const response = await fetch('https://api.together.xyz/v1/models', {
        headers: {
          'Authorization': `Bearer ${apiKey}`,
          'Content-Type': 'application/json'
        }
      });
      return response.ok;
    } catch {
      return false;
    }
  }

  async generateResponse(query: string, context: string): Promise<string> {
    const apiKey = this.getApiKey();
    if (!apiKey) throw new Error('API key n√£o configurada');

    const prompt = `Voc√™ √© um assistente especializado em an√°lise de talentos tecnol√≥gicos para a HITSS.

CONTEXTO DOS PROFISSIONAIS:
${context}

PERGUNTA: ${query}

Forne√ßa insights valiosos e sugest√µes pr√°ticas baseadas nos dados.`;

    try {
      const response = await fetch('https://api.together.xyz/v1/chat/completions', {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${apiKey}`,
          'Content-Type': 'application/json'
        },
        body: JSON.stringify({
          model: this.model,
          messages: [
            {
              role: 'user',
              content: prompt
            }
          ],
          max_tokens: 500,
          temperature: 0.7
        })
      });

      if (!response.ok) {
        throw new Error(`HTTP ${response.status}`);
      }

      const data = await response.json();
      return data.choices[0]?.message?.content || 'N√£o foi poss√≠vel gerar uma resposta.';
    } catch (error) {
      throw new Error(`Erro na API Together.xyz: ${error}`);
    }
  }
}

// Sistema inteligente que testa e usa a melhor op√ß√£o dispon√≠vel
class SmartAI {
  private providers: AIProvider[] = [
    new GroqAI(),        // Mais r√°pido (200-500ms)
    new TogetherAI(),    // Premium com API key
    new LlamaFreeAI(),   // Gratuito sem API key
    new OfflineAI()      // Sempre dispon√≠vel
  ];

  async generateResponse(query: string, professionals: Professional[]): Promise<AIResponse> {
    const startTime = Date.now();
    
    // Preparar contexto dos profissionais
    const context = this.prepareContext(professionals);
    
    // Testar providers em ordem de prefer√™ncia
    for (const provider of this.providers) {
      try {
        console.log(`ü§ñ Testando provider: ${provider.name}`);
        
        const isAvailable = await provider.isAvailable();
        if (!isAvailable) {
          console.log(`‚ùå ${provider.name} n√£o dispon√≠vel`);
          continue;
        }

        console.log(`‚úÖ ${provider.name} dispon√≠vel, gerando resposta...`);
        const message = await provider.generateResponse(query, context);
        const responseTime = Date.now() - startTime;
        
        console.log(`üéâ Resposta gerada via ${provider.name} em ${responseTime}ms`);
        
        return {
          message,
          provider: provider.name as any,
          timestamp: new Date(),
          responseTime
        };
        
      } catch (error) {
        console.log(`‚ùå Erro no ${provider.name}:`, error);
        continue;
      }
    }
    
    // Se chegou at√© aqui, algo deu muito errado
    throw new Error('Nenhum provider de IA dispon√≠vel');
  }

  private prepareContext(professionals: Professional[]): string {
    if (!professionals.length) {
      return 'Nenhum profissional encontrado na base de dados.';
    }

    const summary = `Total de profissionais: ${professionals.length}

Principais tecnologias:
${this.getTechStats(professionals)}

Distribui√ß√£o por senioridade:
${this.getSeniorityStats(professionals)}

Disponibilidade para compartilhamento:
${this.getAvailabilityStats(professionals)}`;

    return summary;
  }

  private getTechStats(professionals: Professional[]): string {
    const techs = ['javascript', 'python', 'java', 'react', 'angular', 'aws', 'azure'];
    const stats = techs.map(tech => {
      const count = professionals.filter(p => 
        p[tech as keyof Professional] === 'Sim' || 
        p[tech as keyof Professional] === 'Avan√ßado' ||
        p[tech as keyof Professional] === 'Intermedi√°rio'
      ).length;
      return `- ${tech}: ${count} profissionais`;
    }).filter(stat => !stat.includes(': 0'));

    return stats.join('\n');
  }

  private getSeniorityStats(professionals: Professional[]): string {
    const levels = ['Junior', 'Pleno', 'Senior', 'Especialista'];
    return levels.map(level => {
      const count = professionals.filter(p => 
        p.proficiencia_cargo?.toLowerCase().includes(level.toLowerCase())
      ).length;
      return `- ${level}: ${count} profissionais`;
    }).filter(stat => !stat.includes(': 0')).join('\n');
  }

  private getAvailabilityStats(professionals: Professional[]): string {
    const available = professionals.filter(p => p.disponivel_compartilhamento).length;
    const percentages = ['100', '75', '50', '25'];
    
    let stats = `- Dispon√≠veis: ${available} de ${professionals.length}\n`;
    
    percentages.forEach(percent => {
      const count = professionals.filter(p => 
        p.percentual_compartilhamento === percent
      ).length;
      if (count > 0) {
        stats += `- ${percent}%: ${count} profissionais\n`;
      }
    });

    return stats;
  }
}

// Inst√¢ncia singleton
export const smartAI = new SmartAI();

// Hook para uso em componentes React
export const useSmartAI = () => {
  const generateResponse = async (query: string, professionals: Professional[]): Promise<AIResponse> => {
    return await smartAI.generateResponse(query, professionals);
  };

  return { generateResponse };
}; 